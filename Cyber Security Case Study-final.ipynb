{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Network classification case study.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNtb/0H3fiSNU2KWcP048Ou",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lalit-kumr/Cyber-Security-Case-Study/blob/main/Cyber%20Security%20Case%20Study-final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFL5OxF-ShtZ"
      },
      "source": [
        "##NETWORK INTRUSION DETECTION\n",
        "\n",
        "### Your task to build network intrusion detection system to detect anamolies and attacks in the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDwfSE3c5nqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8367cdcc-2c70-4297-ac74-7cec1e38daee"
      },
      "source": [
        "# importing importing modules\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import imblearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKuWxx1tUhvG"
      },
      "source": [
        "### Importing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmibBMcGSrX2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "cd18293c-6737-4f6e-fc37-b53863794a7e"
      },
      "source": [
        "smurf = pd.read_csv('https://github.com/lalit-kumr/Cyber-Security-Case-Study/raw/main/Data_of_Attack_Back_Smurf.csv')\n",
        "satan = pd.read_csv('https://github.com/lalit-kumr/Cyber-Security-Case-Study/raw/main/Data_of_Attack_Back_Satan.csv')\n",
        "root_kit = pd.read_csv('https://github.com/lalit-kumr/Cyber-Security-Case-Study/raw/main/Data_of_Attack_Back_RootKit.csv')\n",
        "port_sweep = pd.read_csv('https://github.com/lalit-kumr/Cyber-Security-Case-Study/raw/main/Data_of_Attack_Back_PortSweep.csv')\n",
        "normal = pd.read_csv('https://github.com/lalit-kumr/Cyber-Security-Case-Study/raw/main/Data_of_Attack_Back_Normal.csv')\n",
        "neptune = pd.read_csv('https://github.com/lalit-kumr/Cyber-Security-Case-Study/raw/main/Data_of_Attack_Back_Neptune.csv')\n",
        "nmap = pd.read_csv('https://github.com/lalit-kumr/Cyber-Security-Case-Study/raw/main/Data_of_Attack_Back_NMap.csv')\n",
        "guess_pass = pd.read_csv('https://github.com/lalit-kumr/Cyber-Security-Case-Study/raw/main/Data_of_Attack_Back_GuessPassword.csv')\n",
        "ftp_write = pd.read_csv('https://github.com/lalit-kumr/Cyber-Security-Case-Study/raw/main/Data_of_Attack_Back_FTPWrite.csv ')\n",
        "buffer_overflow = pd.read_csv('https://github.com/lalit-kumr/Cyber-Security-Case-Study/raw/main/Data_of_Attack_Back_BufferOverflow.csv')\n",
        "back = pd.read_csv('https://github.com/lalit-kumr/Cyber-Security-Case-Study/raw/main/Data_of_Attack_Back.csv')\n",
        "back.head()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attack</th>\n",
              "      <th>duration</th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>num_compromised</th>\n",
              "      <th>root_shell</th>\n",
              "      <th>su_attempted</th>\n",
              "      <th>num_root</th>\n",
              "      <th>num_file_creations</th>\n",
              "      <th>num_shells</th>\n",
              "      <th>num_access_files</th>\n",
              "      <th>num_outbound_cmds</th>\n",
              "      <th>is_host_login</th>\n",
              "      <th>is_guest_login</th>\n",
              "      <th>count</th>\n",
              "      <th>srv_count</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>srv_error_rate</th>\n",
              "      <th>rerror_rate</th>\n",
              "      <th>srv_rerror_rate</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>diff_srv_rate</th>\n",
              "      <th>srv_diff_host_rate</th>\n",
              "      <th>dst_host_count</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_same_src_port_rate</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>back</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5454</td>\n",
              "      <td>0.08314</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>back</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5454</td>\n",
              "      <td>0.08314</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.033</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.067</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>back</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5454</td>\n",
              "      <td>0.08314</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.033</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>back</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5454</td>\n",
              "      <td>0.08314</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>back</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5454</td>\n",
              "      <td>0.08314</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  attack  duration  ...   dst_host_rerror_rate   dst_host_srv_rerror_rate\n",
              "0   back       0.0  ...                    0.0                        0.0\n",
              "1   back       0.0  ...                    0.0                        0.0\n",
              "2   back       0.0  ...                    0.0                        0.0\n",
              "3   back       0.0  ...                    0.0                        0.0\n",
              "4   back       0.0  ...                    0.0                        0.0\n",
              "\n",
              "[5 rows x 42 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfZHolKeUkzD"
      },
      "source": [
        "### Joining df's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf0L6qfhS9y0"
      },
      "source": [
        "list_of_df = [smurf,\n",
        "              satan,\n",
        "              root_kit,\n",
        "              port_sweep,\n",
        "              normal,\n",
        "              neptune,\n",
        "              nmap,\n",
        "              guess_pass,\n",
        "              ftp_write ,\n",
        "              buffer_overflow,\n",
        "              back]\n",
        "\n",
        "\n",
        "df = pd.concat(list_of_df, ignore_index=True, sort=False)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaqb93H7Tfu-"
      },
      "source": [
        "### Creating a new column called activity\n",
        "- if df.attack is normal, then '*normal*'\n",
        "- if df.attack is anykind of attack, then '*attack*' "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM0iiJ86TfAe"
      },
      "source": [
        "df['activity'] = np.where(df['attack']=='normal','normal','attack')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "MzI6vVSQUPN8",
        "outputId": "dfebee6b-7d9b-4bab-f5a3-01d87844b8eb"
      },
      "source": [
        "df.select_dtypes(include=['O'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attack</th>\n",
              "      <th>activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>smurf</td>\n",
              "      <td>attack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>smurf</td>\n",
              "      <td>attack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>smurf</td>\n",
              "      <td>attack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>smurf</td>\n",
              "      <td>attack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>smurf</td>\n",
              "      <td>attack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817546</th>\n",
              "      <td>back</td>\n",
              "      <td>attack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817547</th>\n",
              "      <td>back</td>\n",
              "      <td>attack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817548</th>\n",
              "      <td>back</td>\n",
              "      <td>attack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817549</th>\n",
              "      <td>back</td>\n",
              "      <td>attack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817550</th>\n",
              "      <td>back</td>\n",
              "      <td>attack</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>817551 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       attack activity\n",
              "0       smurf   attack\n",
              "1       smurf   attack\n",
              "2       smurf   attack\n",
              "3       smurf   attack\n",
              "4       smurf   attack\n",
              "...       ...      ...\n",
              "817546   back   attack\n",
              "817547   back   attack\n",
              "817548   back   attack\n",
              "817549   back   attack\n",
              "817550   back   attack\n",
              "\n",
              "[817551 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXNK8u9QSe7c"
      },
      "source": [
        "### NA values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUk2PoXdVPYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa8c7c88-bb8e-4251-c698-1aba1078e5d8"
      },
      "source": [
        "df.isna().sum()\n",
        "\n",
        "#no na values"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "attack                          0\n",
              "duration                        0\n",
              " protocol_type                  0\n",
              " service                        0\n",
              " flag                           0\n",
              " src_bytes                      0\n",
              " dst_bytes                      0\n",
              " land                           0\n",
              " wrong_fragment                 0\n",
              " urgent                         0\n",
              " hot                            0\n",
              " num_failed_logins              0\n",
              " logged_in                      0\n",
              " num_compromised                0\n",
              " root_shell                     0\n",
              " su_attempted                   0\n",
              " num_root                       0\n",
              " num_file_creations             0\n",
              " num_shells                     0\n",
              " num_access_files               0\n",
              " num_outbound_cmds              0\n",
              " is_host_login                  0\n",
              " is_guest_login                 0\n",
              " count                          0\n",
              " srv_count                      0\n",
              " serror_rate                    0\n",
              " srv_error_rate                 0\n",
              " rerror_rate                    0\n",
              " srv_rerror_rate                0\n",
              " same_srv_rate                  0\n",
              " diff_srv_rate                  0\n",
              " srv_diff_host_rate             0\n",
              " dst_host_count                 0\n",
              " dst_host_srv_count             0\n",
              " dst_host_same_srv_rate         0\n",
              " dst_host_diff_srv_rate         0\n",
              " dst_host_same_src_port_rate    0\n",
              " dst_host_srv_diff_host_rate    0\n",
              " dst_host_serror_rate           0\n",
              " dst_host_srv_serror_rate       0\n",
              " dst_host_rerror_rate           0\n",
              " dst_host_srv_rerror_rate       0\n",
              "activity                        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjFk9PpOSiRV"
      },
      "source": [
        "### Label encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "l8-FA26GW46_",
        "outputId": "a4dfb4f9-3424-48cc-a92c-501d33bad636"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "\n",
        "df_cat = df.select_dtypes(include='O')\n",
        "df_cat = df_cat.apply(encoder.fit_transform)\n",
        "df_cat\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attack</th>\n",
              "      <th>activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817546</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817547</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817548</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817549</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817550</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>817551 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        attack  activity\n",
              "0           10         0\n",
              "1           10         0\n",
              "2           10         0\n",
              "3           10         0\n",
              "4           10         0\n",
              "...        ...       ...\n",
              "817546       0         0\n",
              "817547       0         0\n",
              "817548       0         0\n",
              "817549       0         0\n",
              "817550       0         0\n",
              "\n",
              "[817551 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ulxiJFwhgAnx",
        "outputId": "723c5fac-6a75-4f1f-fde7-00299be35507"
      },
      "source": [
        "#for binomial classification we will drop the attack variable\n",
        "\n",
        "target = df_cat.drop(labels='attack',axis=1)\n",
        "target"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817546</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817547</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817548</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817549</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817550</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>817551 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        activity\n",
              "0              0\n",
              "1              0\n",
              "2              0\n",
              "3              0\n",
              "4              0\n",
              "...          ...\n",
              "817546         0\n",
              "817547         0\n",
              "817548         0\n",
              "817549         0\n",
              "817550         0\n",
              "\n",
              "[817551 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf3DFKgNTX2y"
      },
      "source": [
        "#dropping attack and activity from df\n",
        "df.drop(labels=['activity','attack'],axis=1,inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvExjC_HSiWn"
      },
      "source": [
        "### Outlier removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "__C5JMjfTB9f",
        "outputId": "f4036f1c-e9b0-4b67-e49d-2ce504c40178"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>num_compromised</th>\n",
              "      <th>root_shell</th>\n",
              "      <th>su_attempted</th>\n",
              "      <th>num_root</th>\n",
              "      <th>num_file_creations</th>\n",
              "      <th>num_shells</th>\n",
              "      <th>num_access_files</th>\n",
              "      <th>num_outbound_cmds</th>\n",
              "      <th>is_host_login</th>\n",
              "      <th>is_guest_login</th>\n",
              "      <th>count</th>\n",
              "      <th>srv_count</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>srv_error_rate</th>\n",
              "      <th>rerror_rate</th>\n",
              "      <th>srv_rerror_rate</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>diff_srv_rate</th>\n",
              "      <th>srv_diff_host_rate</th>\n",
              "      <th>dst_host_count</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_same_src_port_rate</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>8.175510e+05</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>8.175510e+05</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.000877</td>\n",
              "      <td>0.000570</td>\n",
              "      <td>0.052909</td>\n",
              "      <td>0.020160</td>\n",
              "      <td>0.004961</td>\n",
              "      <td>0.024862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.669496e-07</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002456</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.063812</td>\n",
              "      <td>0.000275</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.001463</td>\n",
              "      <td>0.000284</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000360</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.223165e-07</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>0.059857</td>\n",
              "      <td>0.014078</td>\n",
              "      <td>0.024833</td>\n",
              "      <td>0.024929</td>\n",
              "      <td>0.005355</td>\n",
              "      <td>0.005313</td>\n",
              "      <td>0.073471</td>\n",
              "      <td>0.002939</td>\n",
              "      <td>0.010064</td>\n",
              "      <td>0.166868</td>\n",
              "      <td>0.161651</td>\n",
              "      <td>0.066795</td>\n",
              "      <td>0.003380</td>\n",
              "      <td>0.006148</td>\n",
              "      <td>0.001683</td>\n",
              "      <td>0.024865</td>\n",
              "      <td>0.024852</td>\n",
              "      <td>0.005372</td>\n",
              "      <td>0.005279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.026636</td>\n",
              "      <td>0.002596</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.030959</td>\n",
              "      <td>0.033235</td>\n",
              "      <td>0.066635</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.317904e-04</td>\n",
              "      <td>0.000805</td>\n",
              "      <td>0.041470</td>\n",
              "      <td>0.001618</td>\n",
              "      <td>0.048054</td>\n",
              "      <td>0.010338</td>\n",
              "      <td>0.001752</td>\n",
              "      <td>0.001412</td>\n",
              "      <td>0.031777</td>\n",
              "      <td>0.011742</td>\n",
              "      <td>0.001412</td>\n",
              "      <td>0.006566</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.105968e-04</td>\n",
              "      <td>0.005256</td>\n",
              "      <td>0.091984</td>\n",
              "      <td>0.031403</td>\n",
              "      <td>0.043074</td>\n",
              "      <td>0.043153</td>\n",
              "      <td>0.022330</td>\n",
              "      <td>0.022215</td>\n",
              "      <td>0.041806</td>\n",
              "      <td>0.010127</td>\n",
              "      <td>0.023558</td>\n",
              "      <td>0.102058</td>\n",
              "      <td>0.111642</td>\n",
              "      <td>0.043421</td>\n",
              "      <td>0.008557</td>\n",
              "      <td>0.017460</td>\n",
              "      <td>0.003708</td>\n",
              "      <td>0.043062</td>\n",
              "      <td>0.043151</td>\n",
              "      <td>0.021920</td>\n",
              "      <td>0.022070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.054000</td>\n",
              "      <td>0.017000</td>\n",
              "      <td>0.007000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002170</td>\n",
              "      <td>0.003670</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011000</td>\n",
              "      <td>0.008000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>0.002990</td>\n",
              "      <td>0.019690</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.016000</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.017000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.008000</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.014000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.000000e-01</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000e-01</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.511000</td>\n",
              "      <td>0.511000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            duration  ...   dst_host_srv_rerror_rate\n",
              "count  817551.000000  ...              817551.000000\n",
              "mean        0.000877  ...                   0.005279\n",
              "std         0.026636  ...                   0.022070\n",
              "min         0.000000  ...                   0.000000\n",
              "25%         0.000000  ...                   0.000000\n",
              "50%         0.000000  ...                   0.000000\n",
              "75%         0.000000  ...                   0.000000\n",
              "max         1.000000  ...                   0.100000\n",
              "\n",
              "[8 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "SX2Th_LmS5Ai",
        "outputId": "388e76cb-79c4-4fbf-ff7b-1367c26d5fcd"
      },
      "source": [
        "from scipy.stats.mstats import winsorize\n",
        "# To winsorize data means to set extreme outliers equal to a specified percentile of the data.\n",
        "# For example, a 90% winsorization sets all observations greater than the 95th percentile equal to the\n",
        "# value at the 95th percentile and all observations less than the 5th percentile equal to the value at the 5th percentile.\n",
        "#here the limits=[0.05 ,0.05] are the lower and upper percentile limits respectively\n",
        "\n",
        "\n",
        "for x in df:\n",
        "  df.loc[:,x] = winsorize(df[x], limits=[0.05, 0.05])\n",
        "df.describe()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>num_compromised</th>\n",
              "      <th>root_shell</th>\n",
              "      <th>su_attempted</th>\n",
              "      <th>num_root</th>\n",
              "      <th>num_file_creations</th>\n",
              "      <th>num_shells</th>\n",
              "      <th>num_access_files</th>\n",
              "      <th>num_outbound_cmds</th>\n",
              "      <th>is_host_login</th>\n",
              "      <th>is_guest_login</th>\n",
              "      <th>count</th>\n",
              "      <th>srv_count</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>srv_error_rate</th>\n",
              "      <th>rerror_rate</th>\n",
              "      <th>srv_rerror_rate</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>diff_srv_rate</th>\n",
              "      <th>srv_diff_host_rate</th>\n",
              "      <th>dst_host_count</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_same_src_port_rate</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>817551.0</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>817551.0</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "      <td>817551.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000501</td>\n",
              "      <td>0.040969</td>\n",
              "      <td>0.020121</td>\n",
              "      <td>0.002371</td>\n",
              "      <td>0.018541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.063812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.057863</td>\n",
              "      <td>0.011045</td>\n",
              "      <td>0.024833</td>\n",
              "      <td>0.024929</td>\n",
              "      <td>0.005058</td>\n",
              "      <td>0.005313</td>\n",
              "      <td>0.073511</td>\n",
              "      <td>0.001809</td>\n",
              "      <td>0.008703</td>\n",
              "      <td>0.167028</td>\n",
              "      <td>0.161711</td>\n",
              "      <td>0.066815</td>\n",
              "      <td>0.002555</td>\n",
              "      <td>0.004203</td>\n",
              "      <td>0.001357</td>\n",
              "      <td>0.024865</td>\n",
              "      <td>0.024852</td>\n",
              "      <td>0.004226</td>\n",
              "      <td>0.004651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002182</td>\n",
              "      <td>0.056733</td>\n",
              "      <td>0.030887</td>\n",
              "      <td>0.002813</td>\n",
              "      <td>0.031586</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.048054</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.085761</td>\n",
              "      <td>0.009615</td>\n",
              "      <td>0.043074</td>\n",
              "      <td>0.043153</td>\n",
              "      <td>0.021071</td>\n",
              "      <td>0.022215</td>\n",
              "      <td>0.041736</td>\n",
              "      <td>0.002842</td>\n",
              "      <td>0.018662</td>\n",
              "      <td>0.101803</td>\n",
              "      <td>0.111556</td>\n",
              "      <td>0.043390</td>\n",
              "      <td>0.003306</td>\n",
              "      <td>0.009084</td>\n",
              "      <td>0.001898</td>\n",
              "      <td>0.043062</td>\n",
              "      <td>0.043151</td>\n",
              "      <td>0.017039</td>\n",
              "      <td>0.019391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.054000</td>\n",
              "      <td>0.017000</td>\n",
              "      <td>0.007000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002170</td>\n",
              "      <td>0.003670</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.011000</td>\n",
              "      <td>0.008000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>0.002990</td>\n",
              "      <td>0.019690</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.016000</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.017000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.008000</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.014000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>0.011540</td>\n",
              "      <td>0.117620</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.263000</td>\n",
              "      <td>0.036000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.094000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.007000</td>\n",
              "      <td>0.071000</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.009000</td>\n",
              "      <td>0.035000</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.076000</td>\n",
              "      <td>0.087000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       duration  ...   dst_host_srv_rerror_rate\n",
              "count  817551.0  ...              817551.000000\n",
              "mean        0.0  ...                   0.004651\n",
              "std         0.0  ...                   0.019391\n",
              "min         0.0  ...                   0.000000\n",
              "25%         0.0  ...                   0.000000\n",
              "50%         0.0  ...                   0.000000\n",
              "75%         0.0  ...                   0.000000\n",
              "max         0.0  ...                   0.087000\n",
              "\n",
              "[8 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2fYxWFPSiT4"
      },
      "source": [
        "### Profile report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQSiY8BNfSEH"
      },
      "source": [
        "## Here I am commenting out the profiling code because if you run the code in google colab, it throws an error.\n",
        "\n",
        "# from pandas_profiling import ProfileReport\n",
        "\n",
        "# profile = ProfileReport(df, title=\"Pandas Profiling Report\")\n",
        "# profile.to_file(\"your_report.html\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX4-J9HceAmL"
      },
      "source": [
        "### Standardizing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DBiAo1ReETZ"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idocy2ItaJDh"
      },
      "source": [
        "### Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmD07dI7aJY6",
        "outputId": "e4db77bd-70b6-4372-94b2-7def9db94831"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier()\n",
        "#fit the data to the random forest classifier\n",
        "rfc.fit(df,target.activity)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "-QmWSNxdgvIB",
        "outputId": "cac53dfe-20e4-41b8-ecae-c93486b0d09d"
      },
      "source": [
        "#store the featue importance in dataframe feature_impora\n",
        "feature_imp = pd.DataFrame(index=df.columns,data=rfc.feature_importances_)\n",
        "# renaming column names\n",
        "feature_imp.columns=['imp']\n",
        "# sorting the featues by descending importance\n",
        "feature_imp = feature_imp.sort_values(by='imp',ascending=False)\n",
        "#plotting features having importance > 0\n",
        "feature_imp[feature_imp.imp > 0].plot(figsize=(13,4),kind='bar')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b80fda2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 936x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVpUdz66jp0-"
      },
      "source": [
        "### RFE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEVUx_tMjlcZ",
        "outputId": "dc06a269-f3a9-42f5-e663-fb46fc1582d6"
      },
      "source": [
        "#DO NOT run this cell if you have a light pc, it takes 10 min to run this cell. the columns selected by this cell\n",
        "# are already saved in the next cell.\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "dt_reg = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "rfc_1 = RandomForestClassifier(n_estimators=25)\n",
        "\n",
        "\n",
        "rfe = RFE(estimator=rfc_1, n_features_to_select=10)\n",
        "rfe.fit(df, target.activity)\n",
        "\n",
        "rfe.ranking_\n",
        "\n",
        "\n",
        "# selecting features given by RFE\n",
        "f = rfe.get_support(1) #the most important features\n",
        "selected_x = df[df.columns[f]] # final features`\n",
        "selected_x.columns\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([' service', ' flag', ' src_bytes', ' dst_bytes', ' count', ' srv_count',\n",
              "       ' same_srv_rate', ' diff_srv_rate', ' dst_host_count',\n",
              "       ' dst_host_same_srv_rate'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1DttA-NAzX_"
      },
      "source": [
        "selected_x = df[[' service', ' flag', ' src_bytes', ' dst_bytes', ' count',\n",
        "       ' same_srv_rate', ' diff_srv_rate', ' dst_host_count',\n",
        "       ' dst_host_same_srv_rate', ' dst_host_diff_srv_rate']]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxZte3a0Y21_"
      },
      "source": [
        "### Splitting df and df_cat in train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1yLeI3zY91F"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(selected_x, target.activity, test_size=0.25, random_state=11)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SogpsjG8iJVj"
      },
      "source": [
        "### Training classification models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Zm-th6UY-Xr",
        "outputId": "70c98088-8b02-4f26-ca6c-72bccc77cc50"
      },
      "source": [
        "from sklearn.svm import SVC \n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train KNeighborsClassifier Model\n",
        "K_neighbours_classifier = KNeighborsClassifier(n_jobs=-1)\n",
        "K_neighbours_classifier.fit(X_train, Y_train); \n",
        "\n",
        "# Train LogisticRegression Model\n",
        "LGR_classifier = LogisticRegression(n_jobs=-1, random_state=11)\n",
        "LGR_classifier.fit(X_train, Y_train);\n",
        "\n",
        "            \n",
        "# Train Decision Tree Model\n",
        "Dt_classifier = tree.DecisionTreeClassifier(criterion='entropy', random_state=11)\n",
        "Dt_classifier.fit(X_train, Y_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=11, splitter='best')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fhjYqqfm6Dh"
      },
      "source": [
        "\n",
        "classification_models = {'KNN_classifier': K_neighbours_classifier,\n",
        "                         'Logistic_regresssion_classifier': LGR_classifier,\n",
        "                         'Decision_tree_classifier': Dt_classifier                         \n",
        "                         }\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHwAJtq1iDOO"
      },
      "source": [
        "### Evaluate models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_T_AAtZi_1S",
        "outputId": "a34bd6ea-17e4-4fe3-9587-89152eb60f54"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "for k,v in classification_models.items():\n",
        "  accuracy = metrics.accuracy_score(Y_train,v.predict(X_train))\n",
        "  confusion_matrix = metrics.confusion_matrix(Y_train, v.predict(X_train))\n",
        "  classification = metrics.classification_report(Y_train, v.predict(X_train))\n",
        "  print('--------------------------------{} Model Evaluation--------------------------'.format(k))\n",
        "  print('Accuracy :' '\\n',accuracy) \n",
        "  print('\\n') \n",
        "  print('Confusion matrix:'' \\n', confusion_matrix)\n",
        "  print('\\n')\n",
        "  print('Classification report:' '\\n', classification) \n",
        "  \n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------KNN_classifier Model Evaluation--------------------------\n",
            "Accuracy :\n",
            " 0.9997521050683097\n",
            "\n",
            "\n",
            "Confusion matrix: \n",
            " [[180268    106]\n",
            " [    46 432743]]\n",
            "\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    180374\n",
            "           1       1.00      1.00      1.00    432789\n",
            "\n",
            "    accuracy                           1.00    613163\n",
            "   macro avg       1.00      1.00      1.00    613163\n",
            "weighted avg       1.00      1.00      1.00    613163\n",
            "\n",
            "--------------------------------Logistic_regresssion_classifier Model Evaluation--------------------------\n",
            "Accuracy :\n",
            " 0.9946017616849027\n",
            "\n",
            "\n",
            "Confusion matrix: \n",
            " [[177435   2939]\n",
            " [   371 432418]]\n",
            "\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99    180374\n",
            "           1       0.99      1.00      1.00    432789\n",
            "\n",
            "    accuracy                           0.99    613163\n",
            "   macro avg       1.00      0.99      0.99    613163\n",
            "weighted avg       0.99      0.99      0.99    613163\n",
            "\n",
            "--------------------------------Decision_tree_classifier Model Evaluation--------------------------\n",
            "Accuracy :\n",
            " 0.999990214673749\n",
            "\n",
            "\n",
            "Confusion matrix: \n",
            " [[180370      4]\n",
            " [     2 432787]]\n",
            "\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    180374\n",
            "           1       1.00      1.00      1.00    432789\n",
            "\n",
            "    accuracy                           1.00    613163\n",
            "   macro avg       1.00      1.00      1.00    613163\n",
            "weighted avg       1.00      1.00      1.00    613163\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgTGNsZ2yxAY"
      },
      "source": [
        "### Validationg models with test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnWHCvtytLxJ",
        "outputId": "36a34ca6-bd3c-4940-c599-c5bf70ae0a65"
      },
      "source": [
        "for k,v in classification_models.items():\n",
        "  accuracy = metrics.accuracy_score(Y_test,v.predict(X_test))\n",
        "  confusion_matrix = metrics.confusion_matrix(Y_test, v.predict(X_test))\n",
        "  classification = metrics.classification_report(Y_test, v.predict(X_test))\n",
        "  print('--------------------------------{} Model Validation--------------------------'.format(k))\n",
        "  print('Accuracy :' '\\n',accuracy) \n",
        "  print('\\n') \n",
        "  print('Confusion matrix:'' \\n', confusion_matrix)\n",
        "  print('\\n')\n",
        "  print('Classification report:' '\\n', classification) \n",
        "  "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------KNN_classifier Model Validation--------------------------\n",
            "Accuracy :\n",
            " 0.9997162260015265\n",
            "\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 60425     42]\n",
            " [    16 143905]]\n",
            "\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     60467\n",
            "           1       1.00      1.00      1.00    143921\n",
            "\n",
            "    accuracy                           1.00    204388\n",
            "   macro avg       1.00      1.00      1.00    204388\n",
            "weighted avg       1.00      1.00      1.00    204388\n",
            "\n",
            "--------------------------------Logistic_regresssion_classifier Model Validation--------------------------\n",
            "Accuracy :\n",
            " 0.9946376499598802\n",
            "\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 59503    964]\n",
            " [   132 143789]]\n",
            "\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     60467\n",
            "           1       0.99      1.00      1.00    143921\n",
            "\n",
            "    accuracy                           0.99    204388\n",
            "   macro avg       1.00      0.99      0.99    204388\n",
            "weighted avg       0.99      0.99      0.99    204388\n",
            "\n",
            "--------------------------------Decision_tree_classifier Model Validation--------------------------\n",
            "Accuracy :\n",
            " 0.999843435035325\n",
            "\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 60448     19]\n",
            " [    13 143908]]\n",
            "\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     60467\n",
            "           1       1.00      1.00      1.00    143921\n",
            "\n",
            "    accuracy                           1.00    204388\n",
            "   macro avg       1.00      1.00      1.00    204388\n",
            "weighted avg       1.00      1.00      1.00    204388\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yekYTy4C6MSm"
      },
      "source": [
        "### Multinomial classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Lr4KM5ukzImr",
        "outputId": "9ff5b79c-5054-444e-a009-8e8b558bd125"
      },
      "source": [
        "#storing our targer variabe in a dataframe\n",
        "target_mul_class = df_cat[['attack']]\n",
        "target_mul_class"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attack</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817546</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817547</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817548</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817549</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817550</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>817551 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        attack\n",
              "0           10\n",
              "1           10\n",
              "2           10\n",
              "3           10\n",
              "4           10\n",
              "...        ...\n",
              "817546       0\n",
              "817547       0\n",
              "817548       0\n",
              "817549       0\n",
              "817550       0\n",
              "\n",
              "[817551 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZBQSP_GLIj3",
        "outputId": "19c6116c-bc90-4c87-e528-e0b598301739"
      },
      "source": [
        "#Feature selection using RFE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "dt_reg = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "# rfc_1 = RandomForestClassifier(n_estimators=25)\n",
        "\n",
        "#using decision tree regressor to select the features\n",
        "rfe = RFE(estimator=dt_reg, n_features_to_select=10)\n",
        "rfe.fit(df, target_mul_class.attack)\n",
        "\n",
        "\n",
        "\n",
        "# selecting features given by RFE\n",
        "f = rfe.get_support(1) #the most important features\n",
        "selected_x_mul = df[df.columns[f]] # final features`\n",
        "selected_x_mul.columns"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([' service', ' flag', ' src_bytes', ' count', ' srv_count',\n",
              "       ' serror_rate', ' same_srv_rate', ' dst_host_same_srv_rate',\n",
              "       ' dst_host_same_src_port_rate', ' dst_host_serror_rate'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrFIIw1K6LaG"
      },
      "source": [
        "#Using the same features that we got from RFE and training the models on those features.\n",
        "\n",
        "\n",
        "#splitting the dataset in training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_M_train, X_M_test, Y_M_train, Y_M_test = train_test_split(selected_x_mul, target_mul_class.attack, test_size=0.25, random_state=11)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzQPmnoMVCyT",
        "outputId": "18c941ea-5be1-4042-d205-2b41606c00b2"
      },
      "source": [
        "#Training the models\n",
        "from sklearn.svm import SVC \n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#Train KNeighborsClassifier Model\n",
        "KNN_M = KNeighborsClassifier(n_jobs=-1) \n",
        "KNN_M.fit(X_M_train, Y_M_train)\n",
        "\n",
        "#Train LogisticRegression Model\n",
        "LG_class_M = LogisticRegression(n_jobs=-1, random_state=11) \n",
        "LG_class_M.fit(X_M_train, Y_M_train)\n",
        "\n",
        "#Train Decision Tree Model\n",
        "Dt_classifier_M = tree.DecisionTreeClassifier(criterion='entropy', random_state=11) \n",
        "Dt_classifier_M.fit(X_M_train, Y_M_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=11, splitter='best')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR3fe-os7S8h"
      },
      "source": [
        "multi_class_models = {'KNN_classifier': KNN_M,\n",
        "                         'Logistic_regresssion_classifier': LG_class_M,\n",
        "                         'Decision_tree_classifier': Dt_classifier_M                         \n",
        "                         }"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CACzQI07rMf",
        "outputId": "85adacc0-2921-4e55-f150-b755517f7304"
      },
      "source": [
        "#Model evaluation\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "for k,v in multi_class_models.items():\n",
        "  accuracy = metrics.accuracy_score(Y_M_train,v.predict(X_M_train))\n",
        "  confusion_matrix = metrics.confusion_matrix(Y_M_train, v.predict(X_M_train))\n",
        "  classification = metrics.classification_report(Y_M_train, v.predict(X_M_train))\n",
        "  print('--------------------------------{} Model Evaluation--------------------------'.format(k))\n",
        "  print('Accuracy :' '\\n',accuracy) \n",
        "  print('\\n') \n",
        "  print('Confusion matrix:'' \\n', confusion_matrix)\n",
        "  print('\\n')\n",
        "  print('Classification report:' '\\n', classification) "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------KNN_classifier Model Evaluation--------------------------\n",
            "Accuracy :\n",
            " 0.9996004325114203\n",
            "\n",
            "\n",
            "Confusion matrix: \n",
            " [[   739      0      0      0      0      0      4      0      0      0\n",
            "       0]\n",
            " [     0     13      0      0      0      0      5      1      0      0\n",
            "       0]\n",
            " [     0      0      0      0      0      0      5      0      0      0\n",
            "       0]\n",
            " [     0      0      0     35      1      0      2      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0 170180      1      4      1      0     11\n",
            "       0]\n",
            " [     0      0      0      0      1   1172      7      1      0      2\n",
            "       0]\n",
            " [     4      0      0      1      7      4 432757      2      0     12\n",
            "       2]\n",
            " [     0      0      0      0      5      3      8   2172      0      9\n",
            "       0]\n",
            " [     0      0      0      0      0      0      5      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0     73      1     47      5      0   3618\n",
            "       0]\n",
            " [     0      0      0      0      0      0     10      0      0      1\n",
            "    2232]]\n",
            "\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       743\n",
            "           1       1.00      0.68      0.81        19\n",
            "           2       0.00      0.00      0.00         5\n",
            "           3       0.97      0.92      0.95        38\n",
            "           4       1.00      1.00      1.00    170197\n",
            "           5       0.99      0.99      0.99      1183\n",
            "           6       1.00      1.00      1.00    432789\n",
            "           7       1.00      0.99      0.99      2197\n",
            "           8       0.00      0.00      0.00         5\n",
            "           9       0.99      0.97      0.98      3744\n",
            "          10       1.00      1.00      1.00      2243\n",
            "\n",
            "    accuracy                           1.00    613163\n",
            "   macro avg       0.81      0.78      0.79    613163\n",
            "weighted avg       1.00      1.00      1.00    613163\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------Logistic_regresssion_classifier Model Evaluation--------------------------\n",
            "Accuracy :\n",
            " 0.9888039558812257\n",
            "\n",
            "\n",
            "Confusion matrix: \n",
            " [[     0      0      0      0      0      0    743      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0      0      0     19      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0      0      0      5      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0      0      0     38      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0 170115      1     66      0      0     15\n",
            "       0]\n",
            " [     0      0      0      0    224      0    959      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0     75      3 432643      6      0     30\n",
            "      32]\n",
            " [     0      0      0      0    689      0    111   1278      0    119\n",
            "       0]\n",
            " [     0      0      0      0      0      0      5      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0   2431      0    811      0      0    486\n",
            "      16]\n",
            " [     0      0      0      0      0      0    467      0      0      0\n",
            "    1776]]\n",
            "\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       743\n",
            "           1       0.00      0.00      0.00        19\n",
            "           2       0.00      0.00      0.00         5\n",
            "           3       0.00      0.00      0.00        38\n",
            "           4       0.98      1.00      0.99    170197\n",
            "           5       0.00      0.00      0.00      1183\n",
            "           6       0.99      1.00      1.00    432789\n",
            "           7       1.00      0.58      0.73      2197\n",
            "           8       0.00      0.00      0.00         5\n",
            "           9       0.75      0.13      0.22      3744\n",
            "          10       0.97      0.79      0.87      2243\n",
            "\n",
            "    accuracy                           0.99    613163\n",
            "   macro avg       0.43      0.32      0.35    613163\n",
            "weighted avg       0.98      0.99      0.99    613163\n",
            "\n",
            "--------------------------------Decision_tree_classifier Model Evaluation--------------------------\n",
            "Accuracy :\n",
            " 0.9999608586949963\n",
            "\n",
            "\n",
            "Confusion matrix: \n",
            " [[   743      0      0      0      0      0      0      0      0      0\n",
            "       0]\n",
            " [     0     17      0      0      0      0      2      0      0      0\n",
            "       0]\n",
            " [     0      0      4      0      0      0      1      0      0      0\n",
            "       0]\n",
            " [     0      0      0     38      0      0      0      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0 170195      0      1      0      0      1\n",
            "       0]\n",
            " [     0      0      0      0      0   1183      0      0      0      0\n",
            "       0]\n",
            " [     1      0      0      0      0      3 432785      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0      0      1      2   2193      0      1\n",
            "       0]\n",
            " [     0      0      0      0      0      0      1      0      4      0\n",
            "       0]\n",
            " [     0      0      0      0      1      0      7      2      0   3734\n",
            "       0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "    2243]]\n",
            "\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       743\n",
            "           1       1.00      0.89      0.94        19\n",
            "           2       1.00      0.80      0.89         5\n",
            "           3       1.00      1.00      1.00        38\n",
            "           4       1.00      1.00      1.00    170197\n",
            "           5       1.00      1.00      1.00      1183\n",
            "           6       1.00      1.00      1.00    432789\n",
            "           7       1.00      1.00      1.00      2197\n",
            "           8       1.00      0.80      0.89         5\n",
            "           9       1.00      1.00      1.00      3744\n",
            "          10       1.00      1.00      1.00      2243\n",
            "\n",
            "    accuracy                           1.00    613163\n",
            "   macro avg       1.00      0.95      0.97    613163\n",
            "weighted avg       1.00      1.00      1.00    613163\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-vctbh_7tdB",
        "outputId": "6b826f81-6379-4d09-9597-3212d7016b13"
      },
      "source": [
        "#Model Validation with test sets\n",
        "for k,v in multi_class_models.items():\n",
        "  accuracy = metrics.accuracy_score(Y_M_test,v.predict(X_M_test))\n",
        "  confusion_matrix = metrics.confusion_matrix(Y_M_test, v.predict(X_M_test))\n",
        "  classification = metrics.classification_report(Y_M_test, v.predict(X_M_test))\n",
        "  print('--------------------------------{} Model Validation--------------------------'.format(k))\n",
        "  print('Accuracy :' '\\n',accuracy) \n",
        "  print('\\n') \n",
        "  print('Confusion matrix:'' \\n', confusion_matrix)\n",
        "  print('\\n')\n",
        "  print('Classification report:' '\\n', classification) "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------KNN_classifier Model Validation--------------------------\n",
            "Accuracy :\n",
            " 0.9994079887273225\n",
            "\n",
            "\n",
            "Confusion matrix: \n",
            " [[   222      0      0      0      0      0      3      0      0      0\n",
            "       0]\n",
            " [     0      7      0      0      0      0      3      1      0      0\n",
            "       0]\n",
            " [     0      0      0      0      0      0      3      0      0      0\n",
            "       0]\n",
            " [     0      1      0     13      0      0      1      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0  57024      0      0      1      0      6\n",
            "       0]\n",
            " [     0      0      0      0      0    370      1      0      0      0\n",
            "       0]\n",
            " [     2      0      0      0      2      5 143904      1      0      6\n",
            "       1]\n",
            " [     0      0      0      0      5      2      6    751      0      3\n",
            "       0]\n",
            " [     0      0      0      0      0      1      3      0      0      1\n",
            "       0]\n",
            " [     0      0      0      0     42      3     16      1      0   1213\n",
            "       0]\n",
            " [     0      0      0      0      0      0      1      0      0      0\n",
            "     763]]\n",
            "\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       225\n",
            "           1       0.88      0.64      0.74        11\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       1.00      0.87      0.93        15\n",
            "           4       1.00      1.00      1.00     57031\n",
            "           5       0.97      1.00      0.98       371\n",
            "           6       1.00      1.00      1.00    143921\n",
            "           7       0.99      0.98      0.99       767\n",
            "           8       0.00      0.00      0.00         5\n",
            "           9       0.99      0.95      0.97      1275\n",
            "          10       1.00      1.00      1.00       764\n",
            "\n",
            "    accuracy                           1.00    204388\n",
            "   macro avg       0.80      0.77      0.78    204388\n",
            "weighted avg       1.00      1.00      1.00    204388\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------Logistic_regresssion_classifier Model Validation--------------------------\n",
            "Accuracy :\n",
            " 0.9889523846801183\n",
            "\n",
            "\n",
            "Confusion matrix: \n",
            " [[     0      0      0      0      0      0    225      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0      1      0     10      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0      0      0      3      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0      0      0     15      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0  57005      1     21      0      0      4\n",
            "       0]\n",
            " [     0      0      0      0     71      0    300      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0     29      2 143863      2      0     15\n",
            "      10]\n",
            " [     0      0      0      0    235      0     32    464      0     36\n",
            "       0]\n",
            " [     0      0      0      0      0      0      5      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0    815      0    275      0      0    176\n",
            "       9]\n",
            " [     0      0      0      0      0      0    142      0      0      0\n",
            "     622]]\n",
            "\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       225\n",
            "           1       0.00      0.00      0.00        11\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.00      0.00      0.00        15\n",
            "           4       0.98      1.00      0.99     57031\n",
            "           5       0.00      0.00      0.00       371\n",
            "           6       0.99      1.00      1.00    143921\n",
            "           7       1.00      0.60      0.75       767\n",
            "           8       0.00      0.00      0.00         5\n",
            "           9       0.76      0.14      0.23      1275\n",
            "          10       0.97      0.81      0.89       764\n",
            "\n",
            "    accuracy                           0.99    204388\n",
            "   macro avg       0.43      0.32      0.35    204388\n",
            "weighted avg       0.98      0.99      0.99    204388\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------Decision_tree_classifier Model Validation--------------------------\n",
            "Accuracy :\n",
            " 0.9997309039669648\n",
            "\n",
            "\n",
            "Confusion matrix: \n",
            " [[   225      0      0      0      0      0      0      0      0      0\n",
            "       0]\n",
            " [     0      9      0      0      0      0      2      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0      0      0      3      0      0      0\n",
            "       0]\n",
            " [     0      0      0     14      0      0      1      0      0      0\n",
            "       0]\n",
            " [     0      0      0      0  57028      2      0      0      0      1\n",
            "       0]\n",
            " [     0      0      0      0      0    370      1      0      0      0\n",
            "       0]\n",
            " [     1      1      0      0      3      4 143901      3      0      7\n",
            "       1]\n",
            " [     1      0      0      0      1      0      6    759      0      0\n",
            "       0]\n",
            " [     0      0      0      0      0      0      2      0      0      3\n",
            "       0]\n",
            " [     0      0      0      0      5      0      7      0      0   1263\n",
            "       0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "     764]]\n",
            "\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       225\n",
            "           1       0.90      0.82      0.86        11\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       1.00      0.93      0.97        15\n",
            "           4       1.00      1.00      1.00     57031\n",
            "           5       0.98      1.00      0.99       371\n",
            "           6       1.00      1.00      1.00    143921\n",
            "           7       1.00      0.99      0.99       767\n",
            "           8       0.00      0.00      0.00         5\n",
            "           9       0.99      0.99      0.99      1275\n",
            "          10       1.00      1.00      1.00       764\n",
            "\n",
            "    accuracy                           1.00    204388\n",
            "   macro avg       0.81      0.79      0.80    204388\n",
            "weighted avg       1.00      1.00      1.00    204388\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8CZnNbC8BRX"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}